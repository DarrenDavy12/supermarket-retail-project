{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67522645",
   "metadata": {},
   "source": [
    "# Bronze Layer (Read)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5beb8b",
   "metadata": {},
   "source": [
    "### Bronze â†’ Silver Transformation\n",
    "#### Purpose: Clean raw sales data for analytics use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e938e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PySpark functions\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, regexp_replace, when, to_date\n",
    "\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "\n",
    "# Read Bronze layer \n",
    "\n",
    "bronze_path = \"abfss://bronze@<storage-account>.dfs.core.windows.net/supermarket_sales_raw.csv\"\n",
    "\n",
    "df_bronze = spark.read.option(\"header\", True).option(\"inferSchema\", True).csv(bronze_path)\n",
    "\n",
    "df_bronze.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be261ff2",
   "metadata": {},
   "source": [
    "# Silver Layer Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9f2dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize date formats to yyyy-MM-dd\n",
    "\n",
    "df_clean = df_bronze.withColumn(\n",
    "    \"Order Date\",\n",
    "    when(col(\"Order Date\").rlike(r\"^\\d{1,2}/\\d{1,2}/\\d{4}$\"), to_date(col(\"Order Date\"), \"M/d/yyyy\"))\n",
    "    .when(col(\"Order Date\").rlike(r\"^\\d{2}-\\d{2}-\\d{4}$\"), to_date(col(\"Order Date\"), \"dd-MM-yyyy\"))\n",
    "    .otherwise(None)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aaff271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing critical data\n",
    "\n",
    "df_clean = df_clean.dropna(subset=[\"Order ID\", \"Order Date\", \"Sales\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b63c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to Silver\n",
    "\n",
    "silver_path = \"abfss://silver@<storage-account>.dfs.core.windows.net/supermarket_sales_cleaned/\"\n",
    "\n",
    "df_silver = spark.read.format(\"parquet\").load(silver_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1e6493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the first 20 rows\n",
    "df_silver.show(20)\n",
    "\n",
    "# Showing schema to confirm date column type\n",
    "df_silver.printSchema()\n",
    "\n",
    "# Show table view\n",
    "display(df_silver)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
